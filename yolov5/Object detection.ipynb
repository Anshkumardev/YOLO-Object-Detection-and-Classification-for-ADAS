{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc6dbf16-9647-4c2e-b56d-aa46b8f07575",
   "metadata": {},
   "source": [
    "## Checking PyTorch and CUDA Availability\n",
    "\n",
    "In this code cell, we import the PyTorch library and print out information about the availability of CUDA, the CUDA version, and the PyTorch version. This is useful for verifying that PyTorch is correctly installed and that it can utilize the GPU for computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cc3408-19a9-478a-bf26-95366279432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available()) \n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"PyTorch Version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7748a4c5-3471-47da-a629-b82fd1ac541a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading YOLOv5 Model\n",
    "\n",
    "In this code cell, we load the YOLOv5 model from a local directory using PyTorch's hub module. After loading the model, a confirmation message is printed to indicate that the YOLOv5 model has been successfully loaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db82d40c-2db5-4ccd-a187-21664413d9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.hub.load('D:\\Object Detection\\yolov5', 'yolov5n', source='local')\n",
    "print(\"YOLOv5 model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becb63c6-9c1c-48e9-ae50-6aa025e5f027",
   "metadata": {},
   "source": [
    "## Checking GPU Availability and Details\n",
    "\n",
    "This cell checks the availability of CUDA and prints the number of GPUs available. For each available GPU, it also prints its name, helping to identify the GPUs accessible for running PyTorch operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12feeda-fc37-4e2f-b228-f13e27f58e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ee4806-b5e7-490a-87d0-0aabf8d52093",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training the YOLOv5 Model\n",
    "\n",
    "This cell runs the training script for the YOLOv5 model. Ensure the `data.yaml` file is correctly placed in the `yolov5` directory or provide the correct path to it. The training is configured with an image size of 640, batch size of 16, and runs for 10 epochs. The training weights are initialized with `yolov5n.pt`, and the process runs on device 0 (usually the first GPU). The results are saved in the `runs/train` directory under the name `exp_model-n_img-640`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6005ed-3be6-4ea8-b94a-3b3aa01ca082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Correct paths if necessary\n",
    "data_yaml_path = \"data.yaml\"  # Ensure this file is in the yolov5 directory or provide the correct path\n",
    "\n",
    "%run train.py --img 640 --batch 16  --epochs 10 --data {data_yaml_path} --weights yolov5n.pt --device 0 --project runs/train --name exp_model-n_img-640"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c6cd8-2946-498c-be90-99fb615edcd5",
   "metadata": {},
   "source": [
    "## Object Detection and Visualization with YOLOv5\n",
    "\n",
    "This cell performs object detection on a set of test images using a custom-trained YOLOv5 model and visualizes the results with bounding boxes and labels.\n",
    "\n",
    "1. **Load the YOLOv5 Model**: The model is loaded from the specified path where the custom weights are stored.\n",
    "2. **Define a Function to Draw Bounding Boxes and Labels**: This function draws bounding boxes and labels on the detected objects in the image.\n",
    "3. **Specify Paths**: Set the paths for the directory containing the test images and the directory where the processed images will be saved.\n",
    "4. **Process Test Images**: \n",
    "    - List all image files in the test images directory.\n",
    "    - For each image, apply the YOLOv5 model to detect objects.\n",
    "    - Draw bounding boxes and labels on the detected objects.\n",
    "    - Save the processed images to the output directory.\n",
    "    - Optionally, display the processed images.\n",
    "\n",
    "The bounding boxes and labels are drawn using OpenCV, and the processed images are saved to the specified output directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac716e82-6ca0-4b47-97c4-f79c84f7d56e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=r'D:\\Object Detection\\yolov5\\runs\\train\\exp_model-n_img-640\\weights\\last.pt', force_reload=True)\n",
    "\n",
    "# Function to draw bounding boxes and labels\n",
    "def draw_boxes(image, results):\n",
    "    for pred in results.pred[0].detach().cpu().numpy():\n",
    "        x1, y1, x2, y2, conf, cls = pred\n",
    "        label = f\"{model.names[int(cls)]} {conf:.2f}\"\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)  # Change thickness here (last parameter)\n",
    "\n",
    "        # Draw label\n",
    "        (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)  # Adjust font size (third parameter) and thickness (fourth parameter)\n",
    "        cv2.rectangle(image, (int(x1), int(y1) - 20), (int(x1) + w, int(y1)), (0, 255, 0), -1)\n",
    "        cv2.putText(image, label, (int(x1), int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)  # Adjust font size (third parameter) and thickness (fourth parameter)\n",
    "\n",
    "# Path to test images\n",
    "test_images_dir = r\"D:\\Object Detection\\data_test\"  # Use raw string notation\n",
    "output_dir = r'D:\\Object Detection\\output_images_test_set'  # Use raw string notation\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# List all image files in the test images directory\n",
    "image_files = [f for f in os.listdir(test_images_dir) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# Debugging: Print the directory and files being processed\n",
    "print(f\"Processing images from directory: {test_images_dir}\")\n",
    "print(f\"Found image files: {image_files}\")\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(test_images_dir, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Debugging: Print the current image path being processed\n",
    "    print(f\"Processing image: {image_path}\")\n",
    "\n",
    "    # Apply the model to the image\n",
    "    results = model(image)\n",
    "\n",
    "    # Draw bounding boxes and labels\n",
    "    draw_boxes(image, results)\n",
    "\n",
    "    # Save the processed image\n",
    "    output_image_path = os.path.join(output_dir, image_file)\n",
    "    cv2.imwrite(output_image_path, image)\n",
    "\n",
    "    # Display the image (optional)\n",
    "    cv2.imshow('Processed Image', image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7429156-d8fe-448d-a23a-72add1058c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
